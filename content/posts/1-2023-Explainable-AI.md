---
title: "Resources for explainable AI"
date: 2023-01-09T09:13:15Z
draft: false
tags: ["AI", "ML", "Explainable"]
featured_image: "https://github.com/jacobgil/pytorch-grad-cam/blob/master/examples/dogs_gradcam++_resnet50.jpg?raw=true"
---

Here are some explainable AI features that can help to understand why an AI came to a decision. This post will be contantly updated. Keep coming back for more!

* Advanced AI explainability for PyTorch:  https://github.com/jacobgil/pytorch-grad-cam

    This project helps us understand how the AI calculates based on visual cues. This is really good to understand the AI. Project is MIT licensed. 

* AOmniXAI: A Library for Explainable AI: https://github.com/salesforce/OmniXAI

    OmniXAI (short for Omni eXplainable AI) is a Python machine-learning library for explainable AI (XAI), offering omni-way explainable AI and interpretable machine learning capabilities to address many pain points in explaining decisions made by machine learning models in practice. Project is MIT licensed. 
